import tensorflow_hub as hub
import tensorflow as tf
import tensorflow_text as text  # Needed for loading universal-sentence-encoder-cmlm/multilingual-preprocess
import numpy as np
import matplotlib.pyplot as plt


def normalization(embeds):
  norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)
  return embeds/norms

def plot_heatmap(result_matrix):
  height, width = result_matrix.shape
  fig, ax = plt.subplots()
  fig.set_size_inches(8,8)a
  im = ax.imshow(result_matrix)


  # Create X & Y Labels
  ax.set_xticks(np.arange(width))
  ax.set_yticks(np.arange(height))
  ax.set_xticklabels(["Image {}".format(i) for i in range(width)])
  ax.set_yticklabels(["Text {}".format(i) for i in range(height)])

  for i in range(height):
    for j in range(width):
        text = ax.text(j, i, result_matrix[i, j],
                       ha="center", va="center", color='grey', size=20)

  fig.tight_layout()
  plt.show()

if _name_ == '_main_':

    english_sentences = tf.constant(["dog", "Puppies are nice.", "I enjoy taking long walks along the beach with my dog."])
    italian_sentences = tf.constant(["cane", "I cuccioli sono carini.", "Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane."])
    japanese_sentences = tf.constant(["犬", "子犬はいいです", "私は犬と一緒にビーチを散歩するのが好きです"])
    arabic_sentences = tf.constant(["كلب", "الجراء لطيفة.", "أنا أستمتع بالمشي لمسافات طويلة على طول الشاطئ مع كلبي."])


    preprocessor = hub.KerasLayer(
        "https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2")
    encoder = hub.KerasLayer("https://tfhub.dev/google/LaBSE/2")

    english_embeds = encoder(preprocessor(english_sentences))["default"]
    japanese_embeds = encoder(preprocessor(japanese_sentences))["default"]
    italian_embeds = encoder(preprocessor(italian_sentences))["default"]
    arabic_embeds = encoder(preprocessor(arabic_sentences))["default"]
    # For semantic similarity tasks, apply l2 normalization to embeddings
    english_embeds = normalization(english_embeds)
    japanese_embeds = normalization(japanese_embeds)
    italian_embeds = normalization(italian_embeds)
    arabic_embeds = normalization(arabic_embeds)
    print (np.matmul(english_embeds, np.transpose(italian_embeds)))

    # English-Japanese similarity
    print (np.matmul(english_embeds, np.transpose(japanese_embeds)))

    # Italian-Japanese similarity
    print (np.matmul(italian_embeds, np.transpose(japanese_embeds)))
    #English-Arabic similarity
    print (np.matmul(english_embeds, np.transpose(arabic_embeds)))
    plot_heatmap(np.matmul(arabic_embeds, np.transpose(japanese_embeds)))
